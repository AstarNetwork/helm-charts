{{- if .Values.dataSnapshot.backupData }}
kind: CronJob
apiVersion: batch/v1
metadata:
  name: {{ include "node.fullname" . }}
  labels:
    {{- include "node.labels" . | nindent 4 }}
  annotations:
    {{- toYaml .Values.annotations | nindent 4 }}
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 5
  schedule: "{{.Values.dataSnapshot.backupSchedule}}"
  jobTemplate:
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: {{mul 3600 .Values.dataSnapshot.activeDeadlineHours}}
      template:
        metadata:
          annotations:
            {{- with .Values.podAnnotations }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
        spec:
          tolerations:
            {{- with .Values.tolerations }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          affinity:
            podAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                - labelSelector:
                    matchExpressions:
                      - key: "statefulset.kubernetes.io/pod-name"
                        operator: In
                        values:
                          - {{.Values.dataSnapshot.sourcePod}}
                  topologyKey: "kubernetes.io/hostname"

          priorityClassName: system-cluster-critical  #! To evoke if anything else is running there
          serviceAccountName: {{ include "node.serviceAccountName" . }}
          restartPolicy: Never
          hostPID: true
          hostIPC: true
          initContainers:
            - name: mount-data
              image: debian:12-slim
              securityContext:
                runAsUser: 0
                privileged: true
              # env:
              #   - name: APP_HOME
              #     value: "/data"
              command:
                - /bin/bash
                - -xuc
                - |
                  apt update
                  apt install -y curl jq ca-certificates

                  #* Remove the service to remove LB
                  KUBECTL="/tmp/kubectl"
                  curl -Lo $KUBECTL https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl
                  chmod a+x $KUBECTL

                  # #* Check if the node is synced
                  # #* LAST_BLOCK_AGE = now - LastBlockTimestamp
                  # LAST_BLOCK_AGE_SEC=$(($(date +%s)-$(curl -H "Content-Type: application/json" -X POST --data '{"jsonrpc":"2.0","method":"eth_getBlockByNumber","params":["latest", false],"id":67}' localhost:8545|jq -r '.result.timestamp')))
                  # if [ "$LAST_BLOCK_AGE_SEC" -lt "$MAX_BLOCK_AGE_SEC" ]; then
                  #   echo "$i: Node is synced. Coping the data to S3"
                  # else
                  #   echo "$i: Node is not synced. Exiting."
                  #   exit 1
                  # fi

                  #* Create the snapshot
                  SNAP_NAME="node-snapshot"
                  SNAP_YAML=$(mktemp)
                  cat >$SNAP_YAML <<EOF
                  apiVersion: snapshot.storage.k8s.io/v1
                  kind: VolumeSnapshot
                  metadata:
                    name: $SNAP_NAME
                  spec:
                    volumeSnapshotClassName: lvm-localpv
                    source:
                      persistentVolumeClaimName: {{.Values.dataSnapshot.sourcePvcName}}
                  EOF

                  cat $SNAP_YAML
                  $KUBECTL -n {{.Release.Namespace}} apply -f $SNAP_YAML

                  #* Wait for the snapshot to be ready
                  for i in $(seq 1 12); do
                    SNAP_STATUS=$($KUBECTL -n {{.Release.Namespace}} get volumesnapshot $SNAP_NAME -ojson | jq -r '.status.readyToUse')
                    if [ "$SNAP_STATUS" = "true" ]; then
                      echo "Snapshot is ready"
                      break
                    else
                      echo "Snapshot is not ready yet"
                      sleep 5
                    fi
                  done

                  #* VolumeSnapshot is also LVM volume snapshot name
                  SNAP_UID=$($KUBECTL -n {{.Release.Namespace}} get volumesnapshot $SNAP_NAME -ojson | jq -r '.metadata.uid')

                  #* Mount the snapshot
                  nsenter -m/proc/1/ns/mnt -- mkdir -p /mnt/snapshot/data
                  # nsenter -m/proc/1/ns/mnt -- umount /mnt/snapshot/data || true
                  nsenter -m/proc/1/ns/mnt -- mount -o ro /dev/lvm-localpv/$SNAP_UID /mnt/snapshot/data

                  #* Show lvs
                  nsenter -m/proc/1/ns/mnt -- lvs

          containers:
            - name: backup
              image: debian:12-slim
              securityContext:
                runAsUser: 0
                privileged: true
              env:
                - name: AWS_DEFAULT_REGION
                  value: "{{.Values.dataSnapshot.bucketRegion}}"
                - name: RESTIC_PASSWORD
                  value: "astar"
                - name: RESTIC_PROGRESS_FPS
                  value: "0.016666"
                - name: RESTIC_REPOSITORY
                  value: {{ include "node.resticS3Repo" .}}
                - name: RESTIC_HOST
                  value: "{{.Values.ethereumClients}}"
                - name: MAX_BLOCK_AGE_SEC
                  value: "3600"             #* 2h old
              command:
                - /bin/bash
                - -xuc
                - |
                  apt update
                  apt install -y curl jq ca-certificates restic

                  restic self-update
                  if restic check; then
                    echo "Restic repo exist"
                  else
                    echo "Initialising restic repo ..."
                    restic init
                  fi

                  restic unlock --remove-all #! We ensure that only one backup is running so can safely remove the locks

                  #* Backup the data
                  ls /snapshot/data
                  restic backup --no-scan --tag={{.Values.reth.image.tag}}-{{.Values.nimbus.image.tag}} /snapshot/data/reth /snapshot/data/nimbus
                  restic forget --keep-daily {{.Values.dataSnapshot.backupRetainDays}} --prune

                  #* UMount the snapshot
                  nsenter -m/proc/1/ns/mnt -- umount /mnt/snapshot/data

                  #* Delete the snapshot
                  SNAP_NAME="node-snapshot"
                  KUBECTL="/tmp/kubectl"
                  curl -Lo $KUBECTL https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl
                  chmod a+x $KUBECTL
                  $KUBECTL -n {{.Release.Namespace}} delete volumesnapshot $SNAP_NAME
              resources:
                requests:
                  cpu: 1
                  memory: 8Gi
              volumeMounts:
              - mountPath: /snapshot
                name: snapshot-volume
                readOnly: true
          volumes:
            - name: snapshot-volume
              hostPath:
                path: /mnt/snapshot
{{- end }}
